{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MFQZOi1w-_i_eMTS01KceOFk9ubw7uU_",
      "authorship_tag": "ABX9TyMELB6BQaNuEO9rauyxwoBJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WadeShadow/nlp2021/blob/main/Lab2/Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifAPvdFTA_Km"
      },
      "source": [
        "import numpy as np, pandas as pd, tensorflow as tf, requests as rqst, io\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "rnd = np.random.randint\n",
        "\n",
        "folder = '/content/drive/MyDrive/Colab Notebooks/NLP_labs/'"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwIabRAeYeVC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5bc866e-7f05-4b1c-bf49-19845e51a72a"
      },
      "source": [
        "file = open(folder+'sentences.txt')\n",
        "sentences = file.read().split('. ')[:-1]\n",
        "sentences"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Training a virtual agent to outperform human players can teach us how to optimize different processes in a variety of different and exciting subfields',\n",
              " 'This is what Google DeepMind did with its popular AlphaGo, which beat the strongest Go player in history and scored a goal that was considered impossible at the time.In this article, we will develop an AI agent that is able to learn how to play the popular game Snake from scratch',\n",
              " 'To do it, we implement a Deep Reinforcement Learning algorithm using both Keras on top of Tensorflow and PyTorch (both versions are available, you can choose the one you prefer)',\n",
              " 'This approach consists in the interaction between two components: an environment (the game itself) and an agent (Snake)',\n",
              " 'The agent collects information about its current state (we will see later what this means) and performs an action accordingly',\n",
              " 'The environment rewards or punishes the agent based on the performed action',\n",
              " 'Over time, the agent learns what actions maximize the reward (in our case, what actions lead to eating the apple and avoiding the walls)',\n",
              " 'No rules about the game are given',\n",
              " 'Initially, Snake does not know what to do and performs random actions',\n",
              " 'The goal is to elaborate a strategy (technically called “policy”) to maximize the score — or the reward.We are going to see how a Deep Q-Learning algorithm learns to play Snake, scoring up to 50 points and showing a solid strategy in just 5 minutes of training',\n",
              " 'Optionally, the code shows how to optimize the Artificial Neural Network using Bayesian Optimization',\n",
              " 'Reinforcement Learning is a family of algorithms and techniques used for Control (e.g',\n",
              " 'Robotics, Autonomous driving, etc..) and Decision making',\n",
              " 'These approaches solve problems that need to be expressed as a Markov Decision Process (MDP)',\n",
              " 'What does this mean? It means that we need to describe our game by a set of states S (for example, an index based on Snake’s position), a set of actions A (for example, Up, Down, Right, Left), a reward function R (for example, +10 when Snake eats an apple, -10 when Snakes hits a wall) and optionally a transition function T that describes the transitions among states',\n",
              " 'Traditional ML algorithms need to be trained with an input and a “correct answer” called target',\n",
              " 'The system will then try to learn how to predict targets based on unseen inputs',\n",
              " 'In this example, we don’t know the best action to take at each state of the game (this is actually what we are trying to learn!), so a traditional approach would not be effective',\n",
              " 'In Reinforcement Learning, we have two main components: the environment (our game) and the agent (our Snake.',\n",
              " 'or to be correct, the Deep Neural Network that drives our Snake’s actions)',\n",
              " 'Every time the agent performs an action, the environment gives a reward to the agent, which can be positive or negative depending on how good the action was from that specific state',\n",
              " 'The goal of the agent is to learn what actions maximize the reward, given every possible state',\n",
              " 'States are the observations that the agent receives at each iteration from the environment',\n",
              " 'A state can be its position, its speed, or whatever array of variables describes the environment',\n",
              " 'To be more rigorous and to use a Reinforcement Learning notation, the strategy used by the agent to make decisions is called policy',\n",
              " 'On a theoretical level, a policy is a mapping from the state space (the space of all the possible observations that the agent can receive) into the action space (the space of all the actions the agent can take, say UP, DOWN, LEFT and RIGHT)',\n",
              " 'A Q-table is a matrix that correlates the state of the agent with the possible actions that the agent can adopt',\n",
              " 'The values in the table are the action’s probability of success (technically, a measure of the expected cumulative reward), which were updated based on the rewards the agent received during training',\n",
              " 'In the example, we might want to choose RIGHT if we are in State 2, and we might want to go UP if we are in State 4',\n",
              " 'The values in the Q-Table represent the cumulative expected reward of taking action a from a state s',\n",
              " 'In other words, these values give us an indication of the average reward that the agent obtains if it takes action a from that state s',\n",
              " 'This table is the policy of the agent that we mentioned before: it determines what actions should be taken from every state to maximize the expected reward',\n",
              " 'Deep Q-Learning increases the potentiality of Q-Learning by converting the table into Deep Neural Network — that is a powerful representation of a parametrized function',\n",
              " 'When the AI chooses and performs the action, the environment gives a reward to the agent',\n",
              " 'Then, the agent reaches the new state state’ and it updates its Q-value according to the Bellman equation as mentioned above',\n",
              " 'Also, for each move, it stores the original state, the action, the state reached after performed that action, the reward obtained and whether the game ended or not',\n",
              " 'This data is later sampled to train the neural network',\n",
              " 'This operation is called Replay Memory',\n",
              " 'A state is the representation of a situation in which the agent finds itself',\n",
              " 'The state also represents the input of the Neural network',\n",
              " 'the AI tries to maximize the expected reward',\n",
              " 'In our case, a positive reward is only given to the agent when it eats the food target (+10)',\n",
              " 'If the snake hits a wall or hits itself, the reward is negative (-10)',\n",
              " 'Additionally, we could give a positive reward for each step Snake takes without dying',\n",
              " 'In that case, Snake might exploit the situation by running in a circle instead of reaching the food, since it would get positive rewards for each step while avoiding the risk of collision against a wall',\n",
              " 'Sometimes, Reinforcement Learning agents outsmart us, presenting flaws in our strategy that we did not anticipate',\n",
              " 'The brain of the Artificial Intelligence agent uses Deep learning',\n",
              " 'In our case, it consists of 3 hidden layers of 120 neurons',\n",
              " 'The learning rate is not fixed, it starts at 0.0005 and decreases to 0.000005',\n",
              " 'Different architectures and different hyper-parameters contribute to a quicker convergence to an optimum, as well as possible highest scores',\n",
              " 'The network receives as input the state, and returns as output three values related to the three actions: move left, move right, move straight',\n",
              " 'The last layer uses the Softmax function',\n",
              " 'This example shows how a simple agent can learn the mechanism of a process, in this case the game Snake, in a few minutes and with a few lines of code',\n",
              " 'I strongly suggest to dive into the code and to try to improve the result',\n",
              " 'An interesting upgrade might be obtained passing screenshots of the current game for each iteration',\n",
              " 'In that case, the state could be the RGB information for each pixel',\n",
              " 'The Deep Q-Learning model can be replaced with a Double Deep Q-learning algorithm, for a more precise convergence',\n",
              " 'Reinforcement learning is the training of machine learning models to make a sequence of decisions',\n",
              " 'The agent learns to achieve a goal in an uncertain, potentially complex environment',\n",
              " 'In reinforcement learning, an artificial intelligence faces a game-like situation',\n",
              " 'The computer employs trial and error to come up with a solution to the problem',\n",
              " 'To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs',\n",
              " 'Its goal is to maximize the total reward',\n",
              " 'Although the designer sets the reward policy–that is, the rules of the game–he gives the model no hints or suggestions for how to solve the game',\n",
              " 'It’s up to the model to figure out how to perform the task to maximize the reward, starting from totally random trials and finishing with sophisticated tactics and superhuman skills',\n",
              " 'By leveraging the power of search and many trials, reinforcement learning is currently the most effective way to hint machine’s creativity',\n",
              " 'In contrast to human beings, artificial intelligence can gather experience from thousands of parallel gameplays if a reinforcement learning algorithm is run on a sufficiently powerful computer infrastructure',\n",
              " 'in usual circumstances we would require an autonomous vehicle to put safety first, minimize ride time, reduce pollution, offer passengers comfort and obey the rules of law',\n",
              " 'With an autonomous race car, on the other hand, we would emphasize speed much more than the driver’s comfort',\n",
              " 'The programmer cannot predict everything that could happen on the road',\n",
              " 'Instead of building lengthy “if-then” instructions, the programmer prepares the reinforcement learning agent to be capable of learning from the system of rewards and penalties',\n",
              " 'The agent (another name for reinforcement learning algorithms performing the task) gets rewards for reaching specific goals',\n",
              " 'deepsense.ai took part in the “Learning to run” project, which aimed to train a virtual runner from scratch',\n",
              " 'The runner is an advanced and precise musculoskeletal model designed by the Stanford Neuromuscular Biomechanics Laboratory',\n",
              " 'Learning the agent how to run is a first step in building a new generation of prosthetic legs, ones that automatically recognize people’s walking patterns and tweak themselves to make moving easier and more effective',\n",
              " 'While it is possible and has been done in Stanford’s labs, hard-wiring all the commands and predicting all possible patterns of walking requires a lot of work from highly skilled programmers',\n",
              " 'Reinforcement learning, as stated above employs a system of rewards and penalties to compel the computer to solve a problem by itself',\n",
              " 'Human involvement is limited to changing the environment and tweaking the system of rewards and penalties',\n",
              " 'As the computer maximizes the reward, it is prone to seeking unexpected ways of doing it',\n",
              " 'Human involvement is focused on preventing it from exploiting the system and motivating the machine to perform the task in the way expected',\n",
              " 'Reinforcement learning is useful when there is no “proper way” to perform a task, yet there are rules the model has to follow to perform its duties correctly',\n",
              " 'By tweaking and seeking the optimal policy for deep reinforcement learning, we built an agent that in just 20 minutes reached a superhuman level in playing Atari games',\n",
              " 'Similar algorithms in principal can be used to build AI for an autonomous car or a prosthetic leg',\n",
              " 'In fact, one of the best ways to evaluate the reinforcement learning approach is to give the model an Atari video game to play, such as Arkanoid or Space Invaders',\n",
              " 'According to Google Brain’s Marc G',\n",
              " 'Bellemare, who introduced Atari video games as a reinforcement learning benchmark, “although challenging, these environments remain simple enough that we can hope to achieve measurable progress as we attempt to solve them”',\n",
              " 'Deep reinforcement learning, the algorithm used by state-of-the-art game-playing bots, starts by providing an agent with a set of possible actions in the game, a mechanism to receive feedback from the environment, and a goal to pursue',\n",
              " 'Then, through numerous episodes of gameplay, the RL agent gradually goes from taking random actions to learning sequences of actions that can help it maximize its goal',\n",
              " 'Early research of deep reinforcement learning relied on the agent being pretrained on gameplay data from human players',\n",
              " 'More recently, researchers have been able to develop RL agents that can learn games from scratch through pure self-play without human input',\n",
              " 'In their study, the researchers at MIT Lincoln Laboratory were interested in finding out if a reinforcement learning program that outperforms humans could become a reliable coworker to humans',\n",
              " '“At a very high level, this work was inspired by the question: What technology gaps exist that prevent reinforcement learning (RL) from being applied to real-world problems, not just video games?” Dr',\n",
              " 'Ross Allen, AI researcher at Lincoln Laboratory and co-author of the paper, told TechTalks',\n",
              " '“While many such technology gaps exist (e.g., the real world is characterized by uncertainty/partial-observability, data scarcity, ambiguous/nuanced objectives, disparate timescales of decision making, etc.), we identified the need to collaborate with humans as a key technology gap for applying RL in the real-world',\n",
              " 'In fact, in some cases, the reinforcement systems have managed to hack the games and find tricks that baffled even the most talented and experienced human players',\n",
              " 'One famous example was a move made by DeepMind’s AlphaGo in its matchup against Go world champion Lee Sedol',\n",
              " 'Analysts first thought the move was a mistake because it went against the intuitions of human experts',\n",
              " 'But the same move ended up turning the tide in favor of the AI player and defeating Sedol',\n",
              " 'Allen thinks the same kind of ingenuity can come into play when RL is teamed up with humans',\n",
              " '“We think RL can be leveraged to advance the state of the art of human-AI collaboration by avoiding the preconceived assumptions and biases that characterize ‘rule-based expert systems,” Allen said',\n",
              " 'Reinforcement learning is a special branch of AI algorithms that is composed of three key elements: an environment, agents, and rewards',\n",
              " 'By performing actions, the agent changes its own state and that of the environment',\n",
              " 'Based on how much those actions affect the goal the agent must achieve, it is rewarded or penalized',\n",
              " 'In many reinforcement learning problems, the agent has no initial knowledge of the environment and starts by taking random actions',\n",
              " 'Based on the feedback it receives, the agent learns to tune its actions and develop policies that maximize its reward',\n",
              " 'In their paper, the researchers at DeepMind suggest reinforcement learning as the main algorithm that can replicate reward maximization as seen in nature and can eventually lead to artificial general intelligence',\n",
              " '“If an agent can continually adjust its behaviour so as to improve its cumulative reward, then any abilities that are repeatedly demanded by its environment must ultimately be produced in the agent’s behaviour,” the researchers write, adding that, in the course of maximizing for its reward, a good reinforcement learning agent could eventually learn perception, language, social intelligence and so forth',\n",
              " '“We do not offer any theoretical guarantee on the sample efficiency of reinforcement learning agents.” Reinforcement learning is notoriously renowned for requiring huge amounts of data',\n",
              " 'For instance, a reinforcement learning agent might need centuries worth of gameplay to master a computer game',\n",
              " 'And AI researchers still haven’t figured out how to create reinforcement learning systems that can generalize their learnings across several domains',\n",
              " 'Therefore, slight changes to the environment often require the full retraining of the model',\n",
              " 'The researchers also acknowledge that learning mechanisms for reward maximization is an unsolved problem that remains a central question to be further studied in reinforcement learning',\n",
              " 'In “Chip Placement with Deep Reinforcement Learning”, we pose chip placement as a reinforcement learning (RL) problem, where we train an agent (i.e, an RL policy) to optimize the quality of chip placements',\n",
              " 'Unlike prior methods, our approach has the ability to learn from past experience and improve over time',\n",
              " 'In particular, as we train over a greater number of chip blocks, our method becomes better at rapidly generating optimized placements for previously unseen chip blocks',\n",
              " 'Whereas existing baselines require human experts in the loop and take several weeks to generate, our method can generate placements in under six hours that outperform or match their manually designed counterparts']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiLn5tuChnh2"
      },
      "source": [
        "### Підібрати наукові статті за обраним напрямком англійською мовою, з яких вилучити 100 речень, які найбільш відповідають зазначеному напрямку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwYKBe1Ah1Ol",
        "outputId": "383d7a37-d577-442e-b82c-03ddeab590e8"
      },
      "source": [
        "sent_df = []\n",
        "for sent in sentences:\n",
        "  sent_df.append({'Sentence':sent, 'Label':'Reinforcement Learning'})\n",
        "\n",
        "sent_df"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Training a virtual agent to outperform human players can teach us how to optimize different processes in a variety of different and exciting subfields'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'This is what Google DeepMind did with its popular AlphaGo, which beat the strongest Go player in history and scored a goal that was considered impossible at the time.In this article, we will develop an AI agent that is able to learn how to play the popular game Snake from scratch'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'To do it, we implement a Deep Reinforcement Learning algorithm using both Keras on top of Tensorflow and PyTorch (both versions are available, you can choose the one you prefer)'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'This approach consists in the interaction between two components: an environment (the game itself) and an agent (Snake)'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The agent collects information about its current state (we will see later what this means) and performs an action accordingly'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The environment rewards or punishes the agent based on the performed action'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Over time, the agent learns what actions maximize the reward (in our case, what actions lead to eating the apple and avoiding the walls)'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'No rules about the game are given'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Initially, Snake does not know what to do and performs random actions'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The goal is to elaborate a strategy (technically called “policy”) to maximize the score — or the reward.We are going to see how a Deep Q-Learning algorithm learns to play Snake, scoring up to 50 points and showing a solid strategy in just 5 minutes of training'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Optionally, the code shows how to optimize the Artificial Neural Network using Bayesian Optimization'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Reinforcement Learning is a family of algorithms and techniques used for Control (e.g'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Robotics, Autonomous driving, etc..) and Decision making'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'These approaches solve problems that need to be expressed as a Markov Decision Process (MDP)'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'What does this mean? It means that we need to describe our game by a set of states S (for example, an index based on Snake’s position), a set of actions A (for example, Up, Down, Right, Left), a reward function R (for example, +10 when Snake eats an apple, -10 when Snakes hits a wall) and optionally a transition function T that describes the transitions among states'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Traditional ML algorithms need to be trained with an input and a “correct answer” called target'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The system will then try to learn how to predict targets based on unseen inputs'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In this example, we don’t know the best action to take at each state of the game (this is actually what we are trying to learn!), so a traditional approach would not be effective'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In Reinforcement Learning, we have two main components: the environment (our game) and the agent (our Snake.'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'or to be correct, the Deep Neural Network that drives our Snake’s actions)'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Every time the agent performs an action, the environment gives a reward to the agent, which can be positive or negative depending on how good the action was from that specific state'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The goal of the agent is to learn what actions maximize the reward, given every possible state'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'States are the observations that the agent receives at each iteration from the environment'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'A state can be its position, its speed, or whatever array of variables describes the environment'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'To be more rigorous and to use a Reinforcement Learning notation, the strategy used by the agent to make decisions is called policy'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'On a theoretical level, a policy is a mapping from the state space (the space of all the possible observations that the agent can receive) into the action space (the space of all the actions the agent can take, say UP, DOWN, LEFT and RIGHT)'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'A Q-table is a matrix that correlates the state of the agent with the possible actions that the agent can adopt'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The values in the table are the action’s probability of success (technically, a measure of the expected cumulative reward), which were updated based on the rewards the agent received during training'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In the example, we might want to choose RIGHT if we are in State 2, and we might want to go UP if we are in State 4'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The values in the Q-Table represent the cumulative expected reward of taking action a from a state s'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In other words, these values give us an indication of the average reward that the agent obtains if it takes action a from that state s'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'This table is the policy of the agent that we mentioned before: it determines what actions should be taken from every state to maximize the expected reward'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Deep Q-Learning increases the potentiality of Q-Learning by converting the table into Deep Neural Network — that is a powerful representation of a parametrized function'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'When the AI chooses and performs the action, the environment gives a reward to the agent'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Then, the agent reaches the new state state’ and it updates its Q-value according to the Bellman equation as mentioned above'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Also, for each move, it stores the original state, the action, the state reached after performed that action, the reward obtained and whether the game ended or not'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'This data is later sampled to train the neural network'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'This operation is called Replay Memory'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'A state is the representation of a situation in which the agent finds itself'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The state also represents the input of the Neural network'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'the AI tries to maximize the expected reward'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In our case, a positive reward is only given to the agent when it eats the food target (+10)'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'If the snake hits a wall or hits itself, the reward is negative (-10)'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Additionally, we could give a positive reward for each step Snake takes without dying'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In that case, Snake might exploit the situation by running in a circle instead of reaching the food, since it would get positive rewards for each step while avoiding the risk of collision against a wall'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Sometimes, Reinforcement Learning agents outsmart us, presenting flaws in our strategy that we did not anticipate'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The brain of the Artificial Intelligence agent uses Deep learning'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In our case, it consists of 3 hidden layers of 120 neurons'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The learning rate is not fixed, it starts at 0.0005 and decreases to 0.000005'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Different architectures and different hyper-parameters contribute to a quicker convergence to an optimum, as well as possible highest scores'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The network receives as input the state, and returns as output three values related to the three actions: move left, move right, move straight'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The last layer uses the Softmax function'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'This example shows how a simple agent can learn the mechanism of a process, in this case the game Snake, in a few minutes and with a few lines of code'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'I strongly suggest to dive into the code and to try to improve the result'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'An interesting upgrade might be obtained passing screenshots of the current game for each iteration'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In that case, the state could be the RGB information for each pixel'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The Deep Q-Learning model can be replaced with a Double Deep Q-learning algorithm, for a more precise convergence'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Reinforcement learning is the training of machine learning models to make a sequence of decisions'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The agent learns to achieve a goal in an uncertain, potentially complex environment'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In reinforcement learning, an artificial intelligence faces a game-like situation'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The computer employs trial and error to come up with a solution to the problem'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'To get the machine to do what the programmer wants, the artificial intelligence gets either rewards or penalties for the actions it performs'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Its goal is to maximize the total reward'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Although the designer sets the reward policy–that is, the rules of the game–he gives the model no hints or suggestions for how to solve the game'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'It’s up to the model to figure out how to perform the task to maximize the reward, starting from totally random trials and finishing with sophisticated tactics and superhuman skills'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'By leveraging the power of search and many trials, reinforcement learning is currently the most effective way to hint machine’s creativity'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In contrast to human beings, artificial intelligence can gather experience from thousands of parallel gameplays if a reinforcement learning algorithm is run on a sufficiently powerful computer infrastructure'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'in usual circumstances we would require an autonomous vehicle to put safety first, minimize ride time, reduce pollution, offer passengers comfort and obey the rules of law'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'With an autonomous race car, on the other hand, we would emphasize speed much more than the driver’s comfort'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The programmer cannot predict everything that could happen on the road'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Instead of building lengthy “if-then” instructions, the programmer prepares the reinforcement learning agent to be capable of learning from the system of rewards and penalties'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The agent (another name for reinforcement learning algorithms performing the task) gets rewards for reaching specific goals'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'deepsense.ai took part in the “Learning to run” project, which aimed to train a virtual runner from scratch'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The runner is an advanced and precise musculoskeletal model designed by the Stanford Neuromuscular Biomechanics Laboratory'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Learning the agent how to run is a first step in building a new generation of prosthetic legs, ones that automatically recognize people’s walking patterns and tweak themselves to make moving easier and more effective'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'While it is possible and has been done in Stanford’s labs, hard-wiring all the commands and predicting all possible patterns of walking requires a lot of work from highly skilled programmers'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Reinforcement learning, as stated above employs a system of rewards and penalties to compel the computer to solve a problem by itself'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Human involvement is limited to changing the environment and tweaking the system of rewards and penalties'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'As the computer maximizes the reward, it is prone to seeking unexpected ways of doing it'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Human involvement is focused on preventing it from exploiting the system and motivating the machine to perform the task in the way expected'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Reinforcement learning is useful when there is no “proper way” to perform a task, yet there are rules the model has to follow to perform its duties correctly'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'By tweaking and seeking the optimal policy for deep reinforcement learning, we built an agent that in just 20 minutes reached a superhuman level in playing Atari games'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Similar algorithms in principal can be used to build AI for an autonomous car or a prosthetic leg'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In fact, one of the best ways to evaluate the reinforcement learning approach is to give the model an Atari video game to play, such as Arkanoid or Space Invaders'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'According to Google Brain’s Marc G'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Bellemare, who introduced Atari video games as a reinforcement learning benchmark, “although challenging, these environments remain simple enough that we can hope to achieve measurable progress as we attempt to solve them”'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Deep reinforcement learning, the algorithm used by state-of-the-art game-playing bots, starts by providing an agent with a set of possible actions in the game, a mechanism to receive feedback from the environment, and a goal to pursue'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Then, through numerous episodes of gameplay, the RL agent gradually goes from taking random actions to learning sequences of actions that can help it maximize its goal'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Early research of deep reinforcement learning relied on the agent being pretrained on gameplay data from human players'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'More recently, researchers have been able to develop RL agents that can learn games from scratch through pure self-play without human input'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In their study, the researchers at MIT Lincoln Laboratory were interested in finding out if a reinforcement learning program that outperforms humans could become a reliable coworker to humans'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': '“At a very high level, this work was inspired by the question: What technology gaps exist that prevent reinforcement learning (RL) from being applied to real-world problems, not just video games?” Dr'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Ross Allen, AI researcher at Lincoln Laboratory and co-author of the paper, told TechTalks'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': '“While many such technology gaps exist (e.g., the real world is characterized by uncertainty/partial-observability, data scarcity, ambiguous/nuanced objectives, disparate timescales of decision making, etc.), we identified the need to collaborate with humans as a key technology gap for applying RL in the real-world'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In fact, in some cases, the reinforcement systems have managed to hack the games and find tricks that baffled even the most talented and experienced human players'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'One famous example was a move made by DeepMind’s AlphaGo in its matchup against Go world champion Lee Sedol'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Analysts first thought the move was a mistake because it went against the intuitions of human experts'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'But the same move ended up turning the tide in favor of the AI player and defeating Sedol'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Allen thinks the same kind of ingenuity can come into play when RL is teamed up with humans'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': '“We think RL can be leveraged to advance the state of the art of human-AI collaboration by avoiding the preconceived assumptions and biases that characterize ‘rule-based expert systems,” Allen said'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Reinforcement learning is a special branch of AI algorithms that is composed of three key elements: an environment, agents, and rewards'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'By performing actions, the agent changes its own state and that of the environment'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Based on how much those actions affect the goal the agent must achieve, it is rewarded or penalized'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In many reinforcement learning problems, the agent has no initial knowledge of the environment and starts by taking random actions'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Based on the feedback it receives, the agent learns to tune its actions and develop policies that maximize its reward'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In their paper, the researchers at DeepMind suggest reinforcement learning as the main algorithm that can replicate reward maximization as seen in nature and can eventually lead to artificial general intelligence'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': '“If an agent can continually adjust its behaviour so as to improve its cumulative reward, then any abilities that are repeatedly demanded by its environment must ultimately be produced in the agent’s behaviour,” the researchers write, adding that, in the course of maximizing for its reward, a good reinforcement learning agent could eventually learn perception, language, social intelligence and so forth'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': '“We do not offer any theoretical guarantee on the sample efficiency of reinforcement learning agents.” Reinforcement learning is notoriously renowned for requiring huge amounts of data'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'For instance, a reinforcement learning agent might need centuries worth of gameplay to master a computer game'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'And AI researchers still haven’t figured out how to create reinforcement learning systems that can generalize their learnings across several domains'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Therefore, slight changes to the environment often require the full retraining of the model'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'The researchers also acknowledge that learning mechanisms for reward maximization is an unsolved problem that remains a central question to be further studied in reinforcement learning'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In “Chip Placement with Deep Reinforcement Learning”, we pose chip placement as a reinforcement learning (RL) problem, where we train an agent (i.e, an RL policy) to optimize the quality of chip placements'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Unlike prior methods, our approach has the ability to learn from past experience and improve over time'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'In particular, as we train over a greater number of chip blocks, our method becomes better at rapidly generating optimized placements for previously unseen chip blocks'},\n",
              " {'Label': 'Reinforcement Learning',\n",
              "  'Sentence': 'Whereas existing baselines require human experts in the loop and take several weeks to generate, our method can generate placements in under six hours that outperform or match their manually designed counterparts'}]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvM3xNrXhnld"
      },
      "source": [
        "### Створити та зберегти у .csv файл pandas DataFrame з обраних речень із указанням в окремому ствопчику назви напрямку (ця назва має бути однаковою для усіх речень)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LrbHarLTh1nu",
        "outputId": "27b1cbf7-458f-4760-8b95-14caf2ea9611"
      },
      "source": [
        "sent_df = pd.DataFrame(data=sent_df, columns=['Sentence', 'Label'])\n",
        "\n",
        "sent_df.to_csv(folder+'sentences.csv')\n",
        "\n",
        "sent_df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Training a virtual agent to outperform human p...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is what Google DeepMind did with its popu...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>To do it, we implement a Deep Reinforcement Le...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This approach consists in the interaction betw...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The agent collects information about its curre...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>The researchers also acknowledge that learning...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>In “Chip Placement with Deep Reinforcement Lea...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>Unlike prior methods, our approach has the abi...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>In particular, as we train over a greater numb...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>Whereas existing baselines require human exper...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>116 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence                   Label\n",
              "0    Training a virtual agent to outperform human p...  Reinforcement Learning\n",
              "1    This is what Google DeepMind did with its popu...  Reinforcement Learning\n",
              "2    To do it, we implement a Deep Reinforcement Le...  Reinforcement Learning\n",
              "3    This approach consists in the interaction betw...  Reinforcement Learning\n",
              "4    The agent collects information about its curre...  Reinforcement Learning\n",
              "..                                                 ...                     ...\n",
              "111  The researchers also acknowledge that learning...  Reinforcement Learning\n",
              "112  In “Chip Placement with Deep Reinforcement Lea...  Reinforcement Learning\n",
              "113  Unlike prior methods, our approach has the abi...  Reinforcement Learning\n",
              "114  In particular, as we train over a greater numb...  Reinforcement Learning\n",
              "115  Whereas existing baselines require human exper...  Reinforcement Learning\n",
              "\n",
              "[116 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evQ6IhNRhnoL"
      },
      "source": [
        "### Здійснити підготовку набору даних до подальшого моделювання (tokenization&embedding, train_test_split)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qY8jqhDMJPo"
      },
      "source": [
        "### Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "-CkYsz0rMIsQ",
        "outputId": "d2be2a3a-ce22-4c51-8de9-3c809acbbbc7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_split, test_split = train_test_split(sent_df, train_size=0.8, test_size=0.2)\n",
        "train_split"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>A state is the representation of a situation i...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>Learning the agent how to run is a first step ...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>In their study, the researchers at MIT Lincoln...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>It’s up to the model to figure out how to perf...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>And AI researchers still haven’t figured out h...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>in usual circumstances we would require an aut...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>In our case, it consists of 3 hidden layers of...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Different architectures and different hyper-pa...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>In the example, we might want to choose RIGHT ...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Deep Q-Learning increases the potentiality of ...</td>\n",
              "      <td>Reinforcement Learning</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>92 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence                   Label\n",
              "38   A state is the representation of a situation i...  Reinforcement Learning\n",
              "74   Learning the agent how to run is a first step ...  Reinforcement Learning\n",
              "90   In their study, the researchers at MIT Lincoln...  Reinforcement Learning\n",
              "64   It’s up to the model to figure out how to perf...  Reinforcement Learning\n",
              "109  And AI researchers still haven’t figured out h...  Reinforcement Learning\n",
              "..                                                 ...                     ...\n",
              "67   in usual circumstances we would require an aut...  Reinforcement Learning\n",
              "47   In our case, it consists of 3 hidden layers of...  Reinforcement Learning\n",
              "49   Different architectures and different hyper-pa...  Reinforcement Learning\n",
              "28   In the example, we might want to choose RIGHT ...  Reinforcement Learning\n",
              "32   Deep Q-Learning increases the potentiality of ...  Reinforcement Learning\n",
              "\n",
              "[92 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du9yjEGFK0ob"
      },
      "source": [
        "#### Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH2lL0PIh5ZS",
        "outputId": "c8397622-89f9-4da0-e3db-231ea0069faf"
      },
      "source": [
        "max_tokens = 10000\n",
        "\n",
        "tokens_count = 0\n",
        "for sent in sentences:\n",
        "  tokens_count+=len(sent.split())\n",
        "avg_tokens = round(tokens_count/len(sentences))\n",
        "avg_tokens"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaXJGCCyGz-Q",
        "outputId": "e4993acd-be39-4c1c-e1fc-ca8fe1ab2d2a"
      },
      "source": [
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=avg_tokens, # how long should the output sequence of tokens be?\n",
        "                                    pad_to_max_tokens=True)\n",
        "text_vectorizer"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7f2fa9c30dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paj3V5giImTT",
        "outputId": "6b56600c-83c0-4271-c9de-296fb6d40694"
      },
      "source": [
        "text_vectorizer(sent_df['Sentence'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(116, 22), dtype=int64, numpy=\n",
              "array([[ 81,   4, 185, ...,   5, 107,   6],\n",
              "       [ 28,  10,  34, ..., 436,   4,  45],\n",
              "       [  3, 106,  19, ..., 299, 338,  38],\n",
              "       ...,\n",
              "       [349, 501, 564, ...,   0,   0,   0],\n",
              "       [  7, 528,  23, ..., 538, 138,  16],\n",
              "       [328, 686, 787, ..., 138,   7, 351]])>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LuArsSqKAsp",
        "outputId": "1423cb40-cd90-4274-f630-a36c3c9c6038"
      },
      "source": [
        "print(f\"Most Used: {text_vectorizer.get_vocabulary()[:5]}\")\n",
        "print(f\"Most Unused: {text_vectorizer.get_vocabulary()[-5:]}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Used: ['', '[UNK]', 'the', 'to', 'a']\n",
            "Most Unused: ['20', '2', '120', '00005', '0000005']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9Ie2kbVK28D"
      },
      "source": [
        "#### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqX5x1xaKj8g",
        "outputId": "810f2138-6de2-4a39-9c69-2385cedaa4ac"
      },
      "source": [
        "embedding = layers.Embedding(input_dim=max_tokens, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                             input_length=avg_tokens) # how long is each input\n",
        "\n",
        "embedding(text_vectorizer(sent_df['Sentence']))\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(116, 22, 128), dtype=float32, numpy=\n",
              "array([[[ 8.56719911e-04,  2.94237211e-03,  3.09188291e-03, ...,\n",
              "          3.19134034e-02, -3.58311906e-02, -3.45857739e-02],\n",
              "        [ 9.90051031e-03,  4.34108116e-02, -1.88305620e-02, ...,\n",
              "          4.70611714e-02, -1.95220709e-02,  3.78351323e-02],\n",
              "        [ 4.95757498e-02,  3.76892425e-02,  4.54409607e-02, ...,\n",
              "          2.82063968e-02, -3.40144411e-02, -1.66114457e-02],\n",
              "        ...,\n",
              "        [ 4.33415286e-02, -4.69392426e-02, -1.49884000e-02, ...,\n",
              "         -1.36009082e-02, -4.70961928e-02, -2.70201098e-02],\n",
              "        [-1.51169077e-02,  1.48225911e-02, -2.98777968e-03, ...,\n",
              "          2.90144347e-02, -1.01806410e-02, -1.45591274e-02],\n",
              "        [ 4.00232710e-02,  4.59876768e-02, -4.04194109e-02, ...,\n",
              "         -2.90425178e-02,  5.00645489e-03,  3.29445712e-02]],\n",
              "\n",
              "       [[-4.61527221e-02,  3.96432616e-02,  4.16095518e-02, ...,\n",
              "         -4.26623970e-03, -4.65283543e-03,  1.15801096e-02],\n",
              "        [-1.79443732e-02, -1.85789950e-02,  3.89498957e-02, ...,\n",
              "          3.66969816e-02, -1.14935637e-03, -3.19681764e-02],\n",
              "        [ 3.59210633e-02,  3.45602743e-02,  3.76462005e-02, ...,\n",
              "          2.29480602e-02, -4.65915464e-02, -4.24470194e-02],\n",
              "        ...,\n",
              "        [ 3.29055451e-02, -4.49321643e-02,  2.14535482e-02, ...,\n",
              "          4.53535467e-03,  3.56894732e-03, -1.54494271e-02],\n",
              "        [ 9.90051031e-03,  4.34108116e-02, -1.88305620e-02, ...,\n",
              "          4.70611714e-02, -1.95220709e-02,  3.78351323e-02],\n",
              "        [-1.09090656e-03,  9.90683958e-03, -4.11457047e-02, ...,\n",
              "         -2.56024301e-04,  3.19254063e-02,  3.75468172e-02]],\n",
              "\n",
              "       [[ 2.88028233e-02, -4.17737961e-02,  8.45949724e-03, ...,\n",
              "         -2.15701107e-02,  4.16114926e-06, -4.68420386e-02],\n",
              "        [ 1.27977841e-02,  3.92486192e-02, -3.23829651e-02, ...,\n",
              "          1.72964595e-02, -9.99652222e-03,  2.60075666e-02],\n",
              "        [-1.00215785e-02,  7.41804764e-03,  4.16752957e-02, ...,\n",
              "         -2.06680782e-02, -4.93489578e-03, -3.86440642e-02],\n",
              "        ...,\n",
              "        [-3.67874727e-02, -1.12649314e-02, -1.30705722e-02, ...,\n",
              "         -1.42553337e-02,  9.42406803e-03,  2.43192576e-02],\n",
              "        [ 1.18496269e-03,  1.73245333e-02, -2.59455573e-02, ...,\n",
              "         -1.56448595e-02,  3.66191007e-02,  3.60193513e-02],\n",
              "        [ 3.90393399e-02,  4.59128134e-02,  2.11093687e-02, ...,\n",
              "         -4.26502116e-02,  4.13254239e-02, -3.85210514e-02]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-4.29055840e-03, -4.27094102e-02,  4.24307100e-02, ...,\n",
              "         -3.28595042e-02, -1.88255664e-02,  3.79936360e-02],\n",
              "        [ 1.37579441e-03, -8.12895223e-03, -2.87881736e-02, ...,\n",
              "         -4.29509543e-02, -2.25549936e-02,  2.17832662e-02],\n",
              "        [ 5.13242558e-03, -2.58529540e-02,  1.33868344e-02, ...,\n",
              "         -8.78281519e-03, -2.33407747e-02,  4.46414240e-02],\n",
              "        ...,\n",
              "        [ 4.34646718e-02, -1.27442107e-02, -9.74668190e-03, ...,\n",
              "         -3.27295065e-02,  3.39286663e-02, -2.56171227e-02],\n",
              "        [ 4.34646718e-02, -1.27442107e-02, -9.74668190e-03, ...,\n",
              "         -3.27295065e-02,  3.39286663e-02, -2.56171227e-02],\n",
              "        [ 4.34646718e-02, -1.27442107e-02, -9.74668190e-03, ...,\n",
              "         -3.27295065e-02,  3.39286663e-02, -2.56171227e-02]],\n",
              "\n",
              "       [[ 2.60874890e-02,  7.16773421e-03,  5.09657711e-03, ...,\n",
              "         -1.06394179e-02,  1.63340569e-03,  2.20320560e-02],\n",
              "        [-4.26326282e-02, -1.93066839e-02, -4.24281470e-02, ...,\n",
              "          2.96291448e-02, -2.74840482e-02,  3.27358879e-02],\n",
              "        [ 3.16769741e-02,  2.45593227e-02,  5.75748831e-03, ...,\n",
              "          3.23968567e-02, -3.69771495e-02, -2.92467829e-02],\n",
              "        ...,\n",
              "        [ 2.68623568e-02,  2.48059891e-02,  3.45032476e-02, ...,\n",
              "          4.37323116e-02, -4.48971391e-02,  1.12038851e-02],\n",
              "        [-3.58284712e-02, -2.26138365e-02,  2.61603110e-02, ...,\n",
              "          4.92697470e-02, -4.72542308e-02, -2.85846591e-02],\n",
              "        [-1.72170997e-02, -3.09648998e-02, -1.15778558e-02, ...,\n",
              "          2.84147747e-02, -1.11640207e-02,  2.86515392e-02]],\n",
              "\n",
              "       [[ 1.57555602e-02, -9.54478979e-03, -2.94560920e-02, ...,\n",
              "         -4.76711281e-02,  4.87960465e-02, -4.83506694e-02],\n",
              "        [ 5.07168844e-03, -1.39338374e-02, -3.69397774e-02, ...,\n",
              "         -1.91936493e-02, -4.46605347e-02, -2.70228740e-02],\n",
              "        [-8.71621072e-04, -6.38823584e-03,  4.28583287e-02, ...,\n",
              "         -2.37126593e-02, -2.58011352e-02, -3.59352678e-03],\n",
              "        ...,\n",
              "        [-3.58284712e-02, -2.26138365e-02,  2.61603110e-02, ...,\n",
              "          4.92697470e-02, -4.72542308e-02, -2.85846591e-02],\n",
              "        [ 2.60874890e-02,  7.16773421e-03,  5.09657711e-03, ...,\n",
              "         -1.06394179e-02,  1.63340569e-03,  2.20320560e-02],\n",
              "        [-4.99318242e-02, -1.84538253e-02,  4.58640940e-02, ...,\n",
              "          1.01660006e-02,  1.02647170e-02, -5.01415879e-03]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLnYa_i6hn3R"
      },
      "source": [
        "### Відповіді оформити .ipynb, .csv, .pdf документами"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEiSpcGZh8Yl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}